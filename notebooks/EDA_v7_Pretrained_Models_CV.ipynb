{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, concatenate, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model,load_model\n",
    "from keras import initializers\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam, RMSprop, rmsprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import regularizers\n",
    "from time import localtime, strftime\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Data\n",
    "train = pd.read_json(\"../data/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(\"../data/test.json\")\n",
    "test_id = test['id']\n",
    "\n",
    "# Train Set\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], \n",
    "                          X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_train_new = X_train/100+0.5\n",
    "\n",
    "# incident angle:\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "X_train_inc = np.array(train.inc_angle)\n",
    "X_test_inc = np.array(test.inc_angle)\n",
    "X_train_inc_new = X_train_inc/60\n",
    "X_test_inc_new = X_test_inc/60\n",
    "\n",
    "# Test Set\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_test_new = X_test/100+0.5\n",
    "\n",
    "del train, X_band_1, X_band_2, X_band_test_1, X_band_test_2, X_train, X_test, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.models import load_model\n",
    "def getModel():\n",
    "    input_1 = Input(shape=(75,75,3), name = \"image\")\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    model_layer = ZeroPadding2D(padding=(32,32))(input_1)\n",
    "    x = InceptionResNetV2(weights='imagenet', include_top=False, \n",
    "                 input_shape=(139,139,3), classes=1)(model_layer)\n",
    "    #x = base_model.get_layer('block5_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, name='fc2')(merge_one)\n",
    "    merge_one = Activation('relu')(merge_one)\n",
    "    merge_one = Dropout(0.20)(merge_one)\n",
    "    merge_one = Dense(512, name='fc3')(merge_one)\n",
    "    merge_one = Activation('relu')(merge_one)\n",
    "    merge_one = Dropout(0.20)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2], outputs=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call back function\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(preds, name_str):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id']=test_id\n",
    "    submission['is_iceberg']=preds\n",
    "    leaky_angle = [34.4721, 42.5591, 33.6352, 36.1061, 39.2340]\n",
    "    mask = [X_test_inc[i] in leaky_angle for i in range(len(test_id))]\n",
    "    column_name = 'is_iceberg'\n",
    "    submission.loc[mask, column_name] = 1\n",
    "    submission.to_csv('../submit/submission'+name_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "gen = ImageDataGenerator(\n",
    "            rotation_range=20,  \n",
    "            horizontal_flip=True,  \n",
    "            vertical_flip=True,\n",
    "            width_shift_range = 0.1,  \n",
    "            height_shift_range = 0.1,  \n",
    "            zoom_range = 0.1)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CrossValidation(X_train, X_train_inc, steps, learning_rate, decay, K=4):\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "    for j, (train_idx, valid_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j+1)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_valid_cv = X_train[valid_idx]\n",
    "        y_valid_cv = target_train[valid_idx]\n",
    "        \n",
    "        # Incidence Angle\n",
    "        X_inc_cv = X_train_inc[train_idx]\n",
    "        X_inc_valid = X_train_inc[valid_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"../weights_1.hdf5\"\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10)\n",
    "        # Non-Trainable Layers\n",
    "        model = getModel()\n",
    "        #for layer in model.layers[:6]:\n",
    "        #    layer.trainable = False\n",
    "        # optimizer\n",
    "        myoptim=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n",
    "        # compile\n",
    "        model.compile(optimizer=myoptim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_inc_cv, y_train_cv)\n",
    "        \n",
    "        model.fit_generator(\n",
    "                            gen_flow,\n",
    "                            steps_per_epoch = steps,\n",
    "                            epochs = 100,\n",
    "                            shuffle = True,\n",
    "                            verbose = 0,\n",
    "                            validation_data = ([X_valid_cv,X_inc_valid], y_valid_cv),\n",
    "                            callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        model.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = model.evaluate([X_train_cv,X_inc_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = model.evaluate([X_valid_cv,X_inc_valid], y_valid_cv, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=model.predict([X_valid_cv,X_inc_valid])\n",
    "        y_valid_pred_log[valid_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting prediction\n",
    "        temp_test=model.predict([X_test_new, X_test_inc_new])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=model.predict([X_train, X_train_inc])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    #print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    #print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    name_str = strftime(\"%Y%m%d%H%M\", localtime())\n",
    "    with open(\"../experiments/Output.txt\", \"a\") as text_file:\n",
    "        print(\"Submission: {}, Model Name: InceptionResNetV2 with Angle,4 fold, 0 level locked, no drop\".format(name_str), file=text_file)\n",
    "        print(\"Steps per epoch: {}, LR: {}, Decay: {}\".format(steps,learning_rate,decay), file=text_file)\n",
    "        print(\"Train Log Loss: {}\".format(log_loss(target_train, y_train_pred_log)), file=text_file)\n",
    "        print(\"Validation Log Loss: {}\".format(log_loss(target_train, y_valid_pred_log)), file=text_file)\n",
    "        print(\"Leader Board: _______________________________________\", file=text_file)\n",
    "        print(\"\", file=text_file)\n",
    "    submit(y_test_pred_log, name_str)\n",
    "    \n",
    "    cur_time = datetime.datetime.now()\n",
    "    h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "    m, s = divmod(remainder, 60)\n",
    "    time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "    \n",
    "    print(\"Time used: \"+ time_str)\n",
    "    \n",
    "    del y_test_pred_log, y_train_pred_log, temp_train, pred_valid, y_valid_pred_log\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 1\n",
      "Train loss: 0.17487069828\n",
      "Train accuracy: 0.925124791617\n",
      "Test loss: 0.231240165026\n",
      "Test accuracy: 0.900497512734\n",
      "\n",
      "===================FOLD= 2\n",
      "Train loss: 0.137324378043\n",
      "Train accuracy: 0.944305901664\n",
      "Test loss: 0.179264086738\n",
      "Test accuracy: 0.925187032568\n",
      "\n",
      "===================FOLD= 3\n",
      "Train loss: 0.0822022563607\n",
      "Train accuracy: 0.9642560266\n",
      "Test loss: 0.253550042758\n",
      "Test accuracy: 0.902743142591\n",
      "\n",
      "===================FOLD= 4\n",
      "Train loss: 0.0995960175694\n",
      "Train accuracy: 0.966777408242\n",
      "Test loss: 0.251489358544\n",
      "Test accuracy: 0.895\n",
      "Time used: Time 01:25:33\n"
     ]
    }
   ],
   "source": [
    "steps = [128]\n",
    "lrs = [0.001]\n",
    "decays = [0.01]\n",
    "for step in steps:\n",
    "    for lr in lrs:\n",
    "        for decay in decays:\n",
    "            CrossValidation(X_train_new, X_train_inc_new, step, lr, decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 04. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "#submission.to_csv('../submit/submission11072000.csv', index=False)\n",
    "#predicted_test=gmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_angle = [34.4721, 42.5591, 33.6352, 36.1061, 39.2340]\n",
    "mask = [test['inc_angle'][i] in leaky_angle for i in range(len(test))]\n",
    "column_name = 'is_iceberg'\n",
    "submission.loc[mask, column_name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submit/submission11270103.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>3.752710e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>5.634151e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>1.035769e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>9.932595e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>7.357334e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a8d9b1fd</td>\n",
       "      <td>4.966102e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29e7727e</td>\n",
       "      <td>3.668961e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92a51ffb</td>\n",
       "      <td>9.986243e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c769ac97</td>\n",
       "      <td>6.242084e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aee0547d</td>\n",
       "      <td>9.034097e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    is_iceberg\n",
       "0  5941774d  3.752710e-02\n",
       "1  4023181e  5.634151e-01\n",
       "2  b20200e4  1.035769e-03\n",
       "3  e7f018bb  9.932595e-01\n",
       "4  4371c8c3  7.357334e-02\n",
       "5  a8d9b1fd  4.966102e-01\n",
       "6  29e7727e  3.668961e-02\n",
       "7  92a51ffb  9.986243e-01\n",
       "8  c769ac97  6.242084e-10\n",
       "9  aee0547d  9.034097e-15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.725908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.122534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.997053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.075933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d    0.725908\n",
       "1  4023181e    0.122534\n",
       "2  b20200e4    0.000241\n",
       "3  e7f018bb    0.997053\n",
       "4  4371c8c3    0.075933"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = pd.read_csv('../submit/submission201711290031.csv')  # 0.1864\n",
    "s2 = pd.read_csv('../submit/submission201711282325.csv')  # 0.1851\n",
    "s3 = pd.read_csv('../submit/Best Results/submission11270103.csv')  # 0.1818\n",
    "s4 = pd.read_csv('../submit/submission201711270306.csv')  # 0.1771\n",
    "s5 = pd.read_csv('../submit/Best Results/submission11132225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.is_iceberg= s5.is_iceberg*0.75+s1.is_iceberg*0.06+s2.is_iceberg*0.06+s3.is_iceberg*0.06+s4.is_iceberg*0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.to_csv('../submit/ens_test_1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99000000000000021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(s1.is_iceberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
