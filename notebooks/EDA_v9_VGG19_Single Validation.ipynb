{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, concatenate, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model,load_model\n",
    "from keras import initializers\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam, RMSprop, rmsprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import regularizers\n",
    "from time import localtime, strftime\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Data\n",
    "train = pd.read_json(\"../data/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(\"../data/test.json\")\n",
    "test_id = test['id']\n",
    "\n",
    "# Train Set\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], \n",
    "                          X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_train_new = X_train/100+0.5\n",
    "\n",
    "# incident angle:\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "X_train_inc = np.array(train.inc_angle)\n",
    "X_test_inc = np.array(test.inc_angle)\n",
    "X_train_inc_new = X_train_inc/60\n",
    "X_test_inc_new = X_test_inc/60\n",
    "\n",
    "# Test Set\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_test_new = X_test/100+0.5\n",
    "\n",
    "del train, X_band_1, X_band_2, X_band_test_1, X_band_test_2, X_train, X_test, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import load_model\n",
    "def getVgg16Model():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_new.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.2)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.2)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(inputs=[base_model.input, input_2], outputs=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import load_model\n",
    "def getVgg19Model():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_new.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, name='fc2')(merge_one)\n",
    "    #merge_one = BatchNormalization(momentum=0.99)(merge_one)\n",
    "    merge_one = Activation('relu')(merge_one)\n",
    "    merge_one = Dropout(0.2)(merge_one)\n",
    "    merge_one = Dense(512, name='fc3')(merge_one)\n",
    "    #merge_one = BatchNormalization(momentum=0.99)(merge_one)\n",
    "    merge_one = Activation('relu')(merge_one)\n",
    "    merge_one = Dropout(0.2)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(inputs=[base_model.input, input_2], outputs=predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call back function\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(preds, name_str):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id']=test_id\n",
    "    submission['is_iceberg']=preds\n",
    "    leaky_angle = [34.4721, 42.5591, 33.6352, 36.1061, 39.2340]\n",
    "    mask = [X_test_inc[i] in leaky_angle for i in range(len(test_id))]\n",
    "    column_name = 'is_iceberg'\n",
    "    submission.loc[mask, column_name] = 1\n",
    "    submission.to_csv('../submit/submission'+name_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "batch_size = 64\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "gen = ImageDataGenerator(\n",
    "            rotation_range=20,  \n",
    "            horizontal_flip=True,  \n",
    "            vertical_flip=True,\n",
    "            width_shift_range = 0.1,  \n",
    "            height_shift_range = 0.1,  \n",
    "            zoom_range = 0.1)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CrossValidation(X_train, X_train_inc, steps, learning_rate, decay, locked_layer):\n",
    "    X_train_cv, X_valid_cv, X_inc_cv, X_inc_valid, y_train_cv, y_valid_cv = train_test_split(X_train_new, \n",
    "                                        X_train_inc, target_train, random_state=6, train_size=0.75)\n",
    "    \n",
    "    y_test_pred_log = 0\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "\n",
    "    #define file path and get callbacks\n",
    "    file_path = \"../weights_vgg19_angle_2.hdf5\"\n",
    "    callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "    \n",
    "    print(\"Testing lr=\"+str(learning_rate)+\", decay=\"+str(decay)+\", locked_layer=\"+str(locked_layer)+\", steps=\"+str(steps))\n",
    "    # Non-Trainable Layers\n",
    "    model = getVgg19Model()\n",
    "    for layer in model.layers[:locked_layer]:\n",
    "        layer.trainable = False\n",
    "    # optimizer\n",
    "    myoptim=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n",
    "    # compile\n",
    "    model.compile(optimizer=myoptim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    gen_flow = gen_flow_for_two_inputs(X_train_cv, X_inc_cv, y_train_cv)\n",
    "        \n",
    "    model.fit_generator(\n",
    "                        gen_flow,\n",
    "                        steps_per_epoch = steps,\n",
    "                        epochs = 100,\n",
    "                        shuffle = True,\n",
    "                        verbose = 0,\n",
    "                        validation_data = ([X_valid_cv,X_inc_valid], y_valid_cv),\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    #Getting the Best Model\n",
    "    model.load_weights(filepath=file_path)\n",
    "    #Getting Training Score\n",
    "    score = model.evaluate([X_train_cv,X_inc_cv], y_train_cv, verbose=0)\n",
    "    train_score = score[0]\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])\n",
    "    #Getting Test Score\n",
    "    score = model.evaluate([X_valid_cv,X_inc_valid], y_valid_cv, verbose=0)\n",
    "    valid_score = score[0]\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    #Getting prediction\n",
    "    temp_test=model.predict([X_test_new, X_test_inc_new])\n",
    "    y_test_pred_log=temp_test.reshape(temp_test.shape[0])\n",
    "        \n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    name_str = strftime(\"%Y%m%d%H%M\", localtime())\n",
    "    with open(\"../experiments/Output.txt\", \"a\") as text_file:\n",
    "        print(\"Submission: {}, Model Name: VGG19 with Angle, single fold\".format(name_str), file=text_file)\n",
    "        print(\"Steps per epoch: {}, LR: {}, Decay: {}, Locked Layer: {}\".format(steps,learning_rate,decay,locked_layer), file=text_file)\n",
    "        print(\"Train Log Loss: {}\".format(train_score), file=text_file)\n",
    "        print(\"Validation Log Loss: {}\".format(valid_score), file=text_file)\n",
    "        print(\"Leader Board: _______________________________________\", file=text_file)\n",
    "        print(\"\", file=text_file)\n",
    "    submit(y_test_pred_log, name_str)\n",
    "    \n",
    "    cur_time = datetime.datetime.now()\n",
    "    h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "    m, s = divmod(remainder, 60)\n",
    "    time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "    \n",
    "    print(\"Time used: \"+ time_str)\n",
    "    \n",
    "    del y_test_pred_log, temp_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanfeimao/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lr=0.0003, decay=0.0045, locked_layer=4, steps=128\n",
      "Train loss: 0.169537832909\n",
      "Train accuracy: 0.931005818539\n",
      "Test loss: 0.228719607553\n",
      "Test accuracy: 0.917705735809\n",
      "Time used: Time 00:04:25\n",
      "Testing lr=0.0003, decay=0.0045, locked_layer=6, steps=128\n",
      "Train loss: 0.153401768267\n",
      "Train accuracy: 0.944305901664\n",
      "Test loss: 0.222599084947\n",
      "Test accuracy: 0.920199501396\n",
      "Time used: Time 00:05:37\n",
      "Testing lr=0.0003, decay=0.0045, locked_layer=8, steps=128\n",
      "Train loss: 0.16922273698\n",
      "Train accuracy: 0.928512052953\n",
      "Test loss: 0.225358868812\n",
      "Test accuracy: 0.910224439051\n",
      "Time used: Time 00:03:49\n",
      "Testing lr=0.0003, decay=0.0045, locked_layer=10, steps=128\n",
      "Train loss: 0.636238585436\n",
      "Train accuracy: 0.577722361062\n",
      "Test loss: 0.63343708533\n",
      "Test accuracy: 0.561097257898\n",
      "Time used: Time 00:15:51\n",
      "Testing lr=0.0003, decay=0.01, locked_layer=4, steps=128\n",
      "Train loss: 0.161924993754\n",
      "Train accuracy: 0.929343308743\n",
      "Test loss: 0.204706875649\n",
      "Test accuracy: 0.93017456374\n",
      "Time used: Time 00:04:16\n",
      "Testing lr=0.0003, decay=0.01, locked_layer=6, steps=128\n",
      "Train loss: 0.201798298611\n",
      "Train accuracy: 0.914380714979\n",
      "Test loss: 0.234199235899\n",
      "Test accuracy: 0.915211970223\n",
      "Time used: Time 00:03:31\n",
      "Testing lr=0.0003, decay=0.01, locked_layer=8, steps=128\n",
      "Train loss: 0.182385514774\n",
      "Train accuracy: 0.925187032518\n",
      "Test loss: 0.232150998124\n",
      "Test accuracy: 0.910224439051\n",
      "Time used: Time 00:06:50\n",
      "Testing lr=0.0003, decay=0.01, locked_layer=10, steps=128\n",
      "Train loss: 0.189509095062\n",
      "Train accuracy: 0.915211969827\n",
      "Test loss: 0.226007838796\n",
      "Test accuracy: 0.917705735809\n",
      "Time used: Time 00:03:03\n",
      "Testing lr=0.0004, decay=0.0045, locked_layer=4, steps=128\n",
      "Train loss: 0.206488867415\n",
      "Train accuracy: 0.914380714979\n",
      "Test loss: 0.256317004561\n",
      "Test accuracy: 0.897755611121\n",
      "Time used: Time 00:06:29\n",
      "Testing lr=0.0004, decay=0.0045, locked_layer=6, steps=128\n",
      "Train loss: 0.150232796124\n",
      "Train accuracy: 0.94098088123\n",
      "Test loss: 0.211437339795\n",
      "Test accuracy: 0.922693266982\n",
      "Time used: Time 00:04:08\n",
      "Testing lr=0.0004, decay=0.0045, locked_layer=8, steps=128\n",
      "Train loss: 0.199673217084\n",
      "Train accuracy: 0.916043225716\n",
      "Test loss: 0.216187008896\n",
      "Test accuracy: 0.920199501396\n",
      "Time used: Time 00:04:19\n",
      "Testing lr=0.0004, decay=0.0045, locked_layer=10, steps=128\n",
      "Train loss: 0.171070084484\n",
      "Train accuracy: 0.928512053299\n",
      "Test loss: 0.212065074732\n",
      "Test accuracy: 0.925187032568\n",
      "Time used: Time 00:04:48\n",
      "Testing lr=0.0004, decay=0.01, locked_layer=4, steps=128\n",
      "Train loss: 0.173474715857\n",
      "Train accuracy: 0.935993350305\n",
      "Test loss: 0.203772440032\n",
      "Test accuracy: 0.932668329326\n",
      "Time used: Time 00:04:42\n",
      "Testing lr=0.0004, decay=0.01, locked_layer=6, steps=128\n",
      "Train loss: 0.169063408488\n",
      "Train accuracy: 0.931837074428\n",
      "Test loss: 0.231278884032\n",
      "Test accuracy: 0.907730673465\n",
      "Time used: Time 00:10:54\n",
      "Testing lr=0.0004, decay=0.01, locked_layer=8, steps=128\n",
      "Train loss: 0.20708237493\n",
      "Train accuracy: 0.905236908177\n",
      "Test loss: 0.231596648433\n",
      "Test accuracy: 0.915211970223\n",
      "Time used: Time 00:03:28\n",
      "Testing lr=0.0004, decay=0.01, locked_layer=10, steps=128\n",
      "Train loss: 0.195033463903\n",
      "Train accuracy: 0.915211970174\n",
      "Test loss: 0.214673305539\n",
      "Test accuracy: 0.930174563591\n",
      "Time used: Time 00:03:25\n",
      "Testing lr=0.0005, decay=0.0045, locked_layer=4, steps=128\n",
      "Train loss: 0.17139622501\n",
      "Train accuracy: 0.930174563343\n",
      "Test loss: 0.211356874973\n",
      "Test accuracy: 0.935162094912\n",
      "Time used: Time 00:04:26\n",
      "Testing lr=0.0005, decay=0.0045, locked_layer=6, steps=128\n",
      "Train loss: 0.635110678716\n",
      "Train accuracy: 0.571072319499\n",
      "Test loss: 0.631854908127\n",
      "Test accuracy: 0.556109726726\n",
      "Time used: Time 00:07:50\n",
      "Testing lr=0.0005, decay=0.0045, locked_layer=8, steps=128\n",
      "Train loss: 0.1889356251\n",
      "Train accuracy: 0.916874480218\n",
      "Test loss: 0.244781968228\n",
      "Test accuracy: 0.902743142293\n",
      "Time used: Time 00:04:01\n",
      "Testing lr=0.0005, decay=0.0045, locked_layer=10, steps=128\n",
      "Train loss: 0.201358757065\n",
      "Train accuracy: 0.908561928958\n",
      "Test loss: 0.235801285565\n",
      "Test accuracy: 0.917705735809\n",
      "Time used: Time 00:04:02\n",
      "Testing lr=0.0005, decay=0.01, locked_layer=4, steps=128\n",
      "Train loss: 0.188201861687\n",
      "Train accuracy: 0.920199501693\n",
      "Test loss: 0.23778829326\n",
      "Test accuracy: 0.900249376707\n",
      "Time used: Time 00:04:53\n",
      "Testing lr=0.0005, decay=0.01, locked_layer=6, steps=128\n",
      "Train loss: 0.175032461782\n",
      "Train accuracy: 0.928512052953\n",
      "Test loss: 0.219632452377\n",
      "Test accuracy: 0.925187032568\n",
      "Time used: Time 00:04:13\n",
      "Testing lr=0.0005, decay=0.01, locked_layer=8, steps=128\n",
      "Train loss: 0.166825755353\n",
      "Train accuracy: 0.935993350305\n",
      "Test loss: 0.240084019311\n",
      "Test accuracy: 0.912718204786\n",
      "Time used: Time 00:05:42\n",
      "Testing lr=0.0005, decay=0.01, locked_layer=10, steps=128\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,75,75]\n\t [[Node: block1_conv2_23/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_23/Relu, block1_conv2_23/kernel/read)]]\n\t [[Node: loss_23/mul/_18915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1835_loss_23/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'block1_conv2_23/convolution', defined at:\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-db118cff5174>\", line 9, in <module>\n    CrossValidation(X_train_new, X_train_inc_new, step, lr, decay,locked_layer)\n  File \"<ipython-input-9-91a0c2e23e3d>\", line 15, in CrossValidation\n    model = getVgg19Model()\n  File \"<ipython-input-5-c8a417126376>\", line 8, in getVgg19Model\n    input_shape=X_train_new.shape[1:], classes=1)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/applications/vgg19.py\", line 113, in VGG19\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3185, in conv2d\n    data_format=tf_data_format)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,75,75]\n\t [[Node: block1_conv2_23/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_23/Relu, block1_conv2_23/kernel/read)]]\n\t [[Node: loss_23/mul/_18915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1835_loss_23/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,75,75]\n\t [[Node: block1_conv2_23/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_23/Relu, block1_conv2_23/kernel/read)]]\n\t [[Node: loss_23/mul/_18915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1835_loss_23/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-db118cff5174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlocked_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocked_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_inc_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocked_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-91a0c2e23e3d>\u001b[0m in \u001b[0;36mCrossValidation\u001b[0;34m(X_train, X_train_inc, steps, learning_rate, decay, locked_layer)\u001b[0m\n\u001b[1;32m     29\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_inc_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#Getting the Best Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2075\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2076\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,75,75]\n\t [[Node: block1_conv2_23/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_23/Relu, block1_conv2_23/kernel/read)]]\n\t [[Node: loss_23/mul/_18915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1835_loss_23/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'block1_conv2_23/convolution', defined at:\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-db118cff5174>\", line 9, in <module>\n    CrossValidation(X_train_new, X_train_inc_new, step, lr, decay,locked_layer)\n  File \"<ipython-input-9-91a0c2e23e3d>\", line 15, in CrossValidation\n    model = getVgg19Model()\n  File \"<ipython-input-5-c8a417126376>\", line 8, in getVgg19Model\n    input_shape=X_train_new.shape[1:], classes=1)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/applications/vgg19.py\", line 113, in VGG19\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3185, in conv2d\n    data_format=tf_data_format)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/hanfeimao/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,75,75]\n\t [[Node: block1_conv2_23/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_23/Relu, block1_conv2_23/kernel/read)]]\n\t [[Node: loss_23/mul/_18915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1835_loss_23/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "steps = [128]\n",
    "lrs = [0.0004]\n",
    "decays = [0.001, 0.003]\n",
    "locked_layers = [4,6,8,10]\n",
    "for step in steps:\n",
    "    for lr in lrs:\n",
    "        for decay in decays:\n",
    "            for locked_layer in locked_layers:\n",
    "                CrossValidation(X_train_new, X_train_inc_new, step, lr, decay,locked_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 04. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "#submission.to_csv('../submit/submission11072000.csv', index=False)\n",
    "#predicted_test=gmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_angle = [34.4721, 42.5591, 33.6352, 36.1061, 39.2340]\n",
    "mask = [test['inc_angle'][i] in leaky_angle for i in range(len(test))]\n",
    "column_name = 'is_iceberg'\n",
    "submission.loc[mask, column_name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submit/submission11270103.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>3.752710e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>5.634151e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>1.035769e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>9.932595e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>7.357334e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a8d9b1fd</td>\n",
       "      <td>4.966102e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29e7727e</td>\n",
       "      <td>3.668961e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92a51ffb</td>\n",
       "      <td>9.986243e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c769ac97</td>\n",
       "      <td>6.242084e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aee0547d</td>\n",
       "      <td>9.034097e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    is_iceberg\n",
       "0  5941774d  3.752710e-02\n",
       "1  4023181e  5.634151e-01\n",
       "2  b20200e4  1.035769e-03\n",
       "3  e7f018bb  9.932595e-01\n",
       "4  4371c8c3  7.357334e-02\n",
       "5  a8d9b1fd  4.966102e-01\n",
       "6  29e7727e  3.668961e-02\n",
       "7  92a51ffb  9.986243e-01\n",
       "8  c769ac97  6.242084e-10\n",
       "9  aee0547d  9.034097e-15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.725908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.122534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.997053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.075933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d    0.725908\n",
       "1  4023181e    0.122534\n",
       "2  b20200e4    0.000241\n",
       "3  e7f018bb    0.997053\n",
       "4  4371c8c3    0.075933"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = pd.read_csv('../submit/submission201711290031.csv')  # 0.1864\n",
    "s2 = pd.read_csv('../submit/submission201711282325.csv')  # 0.1851\n",
    "s3 = pd.read_csv('../submit/Best Results/submission11270103.csv')  # 0.1818\n",
    "s4 = pd.read_csv('../submit/submission201711270306.csv')  # 0.1771\n",
    "s5 = pd.read_csv('../submit/Best Results/submission11132225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.is_iceberg= s5.is_iceberg*0.75+s1.is_iceberg*0.06+s2.is_iceberg*0.06+s3.is_iceberg*0.06+s4.is_iceberg*0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1.to_csv('../submit/ens_test_1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99000000000000021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(s1.is_iceberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
